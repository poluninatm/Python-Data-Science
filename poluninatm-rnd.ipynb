{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 2411 to 7511\n",
      "Data columns (total 13 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "mean_exam_points       10000 non-null float64\n",
      "choose                 10000 non-null int64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = df.sample(frac=1)\n",
    "features=['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
    "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history',\n",
    "       'mean_exam_points']\n",
    "bool_features=['physics', 'chemistry', 'biology', 'english', 'geography', 'history']\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, label_feature):\n",
    "        self.prediction = self.__predict(data, label_feature)\n",
    "        \n",
    "    def __predict(self, data, label_feature):\n",
    "        classes = data[label_feature].value_counts()\n",
    "        if (1 in classes)==False:\n",
    "            return 0\n",
    "        return classes[1]/len(data)      \n",
    "\n",
    "class Tree: \n",
    "    def __init__(self):\n",
    "        self.tree = []\n",
    "        \n",
    "    def fit(self, data, label_feature, features, bool_features, min_leaf=5):\n",
    "        self.features = features.copy()\n",
    "        self.min_leaf = min_leaf\n",
    "        self.label_feature=label_feature\n",
    "        self.bool_features = bool_features\n",
    "        self.tree = self.__build_tree(data)\n",
    "        \n",
    "    def load(self, tree):\n",
    "        self.tree = tree\n",
    "        \n",
    "    def __split(self, data, feature, t):\n",
    "\n",
    "        left=pd.DataFrame()\n",
    "        right=pd.DataFrame()\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            if row[feature] <= t:\n",
    "                left=left.append(row)\n",
    "            else:\n",
    "                right=right.append(row)\n",
    "                \n",
    "        return left, right\n",
    "    \n",
    "    def __gini(self, labels):\n",
    "        \n",
    "        #  подсчет количества объектов разных классов\n",
    "        classes = {}\n",
    "        \n",
    "        len_labels=len(labels)\n",
    "        classes=labels.value_counts()\n",
    "        \n",
    "        impurity = 1     \n",
    "        for cnt in classes:\n",
    "            p = cnt / len_labels\n",
    "            impurity -= p ** 2\n",
    "\n",
    "        return impurity\n",
    "    \n",
    "    def __find_best_split(self, data, features, current_gini=None):\n",
    "        \n",
    "        if current_gini is None:\n",
    "            current_gini = self.__gini(data[self.label_feature])\n",
    "        \n",
    "\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_feature = None\n",
    "        best_left = None\n",
    "        best_right = None\n",
    "        best_left_gini = None\n",
    "        best_right_gini = None\n",
    "        \n",
    "        for feature in features:\n",
    "           \n",
    "            if feature in self.bool_features:\n",
    "                t_values = [0]\n",
    "            else:\n",
    "                t_values = data[feature].unique()\n",
    "            \n",
    "            \n",
    "            for t in t_values:\n",
    "                left, right =  self.__split(data, feature, t)\n",
    "                \n",
    "                #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "                if len(left) < self.min_leaf or len(right) < self.min_leaf:\n",
    "                    continue\n",
    "\n",
    "                    \n",
    "                p = len(left) / len(data)\n",
    "                left_gini = self.__gini(left[self.label_feature])\n",
    "                right_gini = self.__gini(right[self.label_feature])\n",
    "                current_quality=current_gini - p * left_gini - (1 - p) * right_gini\n",
    "\n",
    "                \n",
    "                #  выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_feature, best_left, best_right, best_left_gini,best_right_gini  = current_quality, t, feature, left, right, left_gini, right_gini\n",
    "                    \n",
    "        return best_quality, best_t, best_feature, best_left, best_right, best_left_gini, best_right_gini\n",
    "    \n",
    "    def __build_tree(self, data, features = None, gini = None, branch = \"center\", level = 0):\n",
    "       \n",
    "        if features is None:\n",
    "            features = self.features\n",
    "            \n",
    "        features = features.copy()\n",
    "        if len(data) > 500:\n",
    "            quality, t, feature, left, right, left_gini, right_gini = self.__find_best_split(data.sample(n=300), features, gini)\n",
    "            if feature is not None:\n",
    "                quality, t, feature, left, right, left_gini, right_gini = self.__find_best_split(data, [feature], gini)\n",
    "            else:\n",
    "                quality, t, feature, left, right, left_gini, right_gini = self.__find_best_split(data, features, gini)\n",
    "        else:\n",
    "            quality, t, feature, left, right, left_gini, right_gini = self.__find_best_split(data, features, gini)\n",
    "\n",
    "        #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "        if quality == 0:\n",
    "            _leaf = Leaf(data, self.label_feature)\n",
    "            return {\"c\":1, \"p\":_leaf.prediction}\n",
    "        \n",
    "        if feature in self.bool_features:\n",
    "            del features[features.index(feature)]\n",
    "        #print((\"-\"*level), branch, feature, t, len(left), len(right))\n",
    "        \n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = self.__build_tree(left, features, left_gini, \"left\", level+1)\n",
    "        false_branch = self.__build_tree(right, features, right_gini, \"right\", level+1)\n",
    "\n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        return {\"c\":0, \"f\":feature, \"p\": t, \"l\":true_branch, \"r\":false_branch}\n",
    "        \n",
    "    def classify_object(self, obj, node = None):\n",
    "        \n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if node[\"c\"]==1:\n",
    "            return node[\"p\"]\n",
    "        \n",
    "        if obj[node[\"f\"]] <= node[\"p\"]:\n",
    "            return self.classify_object(obj, node[\"l\"])\n",
    "        else:\n",
    "            return self.classify_object(obj, node[\"r\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 ms, sys: 865 µs, total: 3.41 ms\n",
      "Wall time: 3.65 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9000, 13), (1000, 13))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# train_data, test_data = train_test_split(df_train,test_size = 0.1,random_state = 1)\n",
    "# train_data.shape, test_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 µs, sys: 83 µs, total: 125 µs\n",
      "Wall time: 93 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "\n",
    "class Forest:\n",
    "    def __init():\n",
    "        self.fits=[]\n",
    "        \n",
    "    def load(self, jsondata):\n",
    "        self.fits=[]\n",
    "        for jsontree in jsondata:\n",
    "            _Tree = Tree()\n",
    "            _Tree.load(jsontree)\n",
    "            self.fits.append(_Tree)\n",
    "            \n",
    "    def fit(self, trees_count, in_trees_samples, rand_features_count, train_data, features, target_feature, bool_features, min_leaf):\n",
    "        \n",
    "        fits=[]\n",
    "        while trees_count > 0:\n",
    "            train=train_data.sample(n=in_trees_samples)\n",
    "            tree = Tree()\n",
    "            \n",
    "            rand_features = random.sample(features, rand_features_count)\n",
    "            \n",
    "            tree.fit(train, target_feature, rand_features, bool_features, min_leaf=3)\n",
    "            fits.append(tree)\n",
    "            trees_count -=1\n",
    "            \n",
    "        self.fits = fits\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        answers=[]\n",
    "        for index, row in test_data.iterrows():\n",
    "            prediction = 0\n",
    "            for f in self.fits:\n",
    "                prediction += f.classify_object(row)\n",
    "            prediction=prediction/len(self.fits)\n",
    "            answers.append(prediction)\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 16s, sys: 5.31 s, total: 24min 22s\n",
      "Wall time: 24min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_Forest = Forest()\n",
    "_Forest.fit(100, 100, 5, train_data, features, \"choose\", bool_features, min_leaf=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.8066877184803392\n",
      "test - 0.84085776179941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = _Forest.predict(train_data)\n",
    "tree_train_score = roc_auc_score(list(train_data[\"choose\"]), predictions)\n",
    "print( f'train - {tree_train_score}')\n",
    "\n",
    "predictions = _Forest.predict(test_data)\n",
    "tree_train_score = roc_auc_score(list(test_data[\"choose\"]), predictions)\n",
    "print( f'test - {tree_train_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "\n",
    "# jsons_trees=[]\n",
    "# for Tree in _Forest.fits:\n",
    "#     jsons_trees.append(Tree.tree)\n",
    "    \n",
    "# with open('fits.json', 'w') as outfile:\n",
    "#     json.dump(jsons_trees, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_test = pd.read_csv('./data/test.csv')\n",
    "df_main_test['choose']=_Forest.predict(df_main_test)\n",
    "df_main_test.loc[:, ['Id', 'choose']].to_csv('TPolunina_predictionsRndF2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = _F.predict(test_data)\n",
    "# tree_train_score = roc_auc_score(list(test_data[\"choose\"]), predictions)\n",
    "# print( f'test - {tree_train_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
